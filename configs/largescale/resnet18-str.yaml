# config to get 90.23% sparse ResNet50 on ImageNet. Modify this file to get other sparse models.
# Architecture
arch: ResNet18

# ===== Dataset ===== #
data: data
set: CIFAR10
name: STR_ResNet18
num_classes: 10

# ===== Learning Rate Policy ======== #
optimizer: sgd
# lr: 0.256
lr: 0.1
# lr_min: 0.01
lr_policy: multistep_lr

# Uncomment in case of Multistep LR
lr_gamma: 0.1
lr_adjust: 30

warmup_length: 10

# ===== Network training config ===== #
epochs: 50
# weight_decay: 0.00002251757813 # Change this according to reported numbers in appendix
weight_decay: 0.0005
# momentum: 0.875
momentum: 0.9
batch_size: 256
# label_smoothing: 0.1
# final_prune_epoch: 30

# ===== STR =========== #
conv_type: STRConvMask
bn_type: LearnedBatchNorm
init: kaiming_normal
mode: fan_in
nonlinearity: relu
sparse_function: sigmoid
sInit_value: -200 # Change this according to reported numbers in appendix
iterations: 2

# ===== Sparse Initialization =========== #
sparse_init: balanced
init_density: 0.5

# ===== GraNet Parameters ========#
sparse: False
method: None
prune_rate: 0.2
# final_density: 0.05
init_prune_epoch: 80
final_prune_epoch: 120
update_frequency: 5
# l2: 0.0005

# ===== Hardware setup ===== #
workers: 2
